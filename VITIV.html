<!--Welcome floating to the virtual perch of my works! 欢迎漂浮到我的虚拟栖息站！-->

<!DOCTYPE html>
<html>
  <head>
    <title>huaxizi</title>
	  <meta name="description" content="V.I.T.I.V.">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  	<link rel="icon" type="image/png" href="images/celluloid.png">
    <link href="style.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&family=Noto+Sans+SC:wght@400;500&display=swap" rel="stylesheet">
  </head>
  <body>
    <div style="position: sticky; top: 1px; margin-right: 45vw; padding: 10px; z-index: 1000;">
      <h1>
        <em style="color:rgb(170, 0, 0);">always virtually floating...</em>.. hua xi zi "cecilia" ... 
      </h1>
    </div>

    <div class="back">
      <h2>
          <a href="index.html" style="color:white">BACK⤴</a> 
      </h2>
    </div>

    <div class="page-img">
      <img src="images/vitiv-site.png" width="500px;" style="margin-top: 30px;">
    </div>

    <div class="page-texts">
      <h2>
        V.I.T.I.V. (2023-ongoing)
      </h2>

      <p>
        A collaborated project with <a href="https://hyanworkspace.github.io/" target="_blank" style="background-color: white; color: purple;">Yan Hui</a> (<a href="https://hyanworkspace.github.io/projects/vitiv_en/" target="_blank" style="background-color: white; color: purple;">here's a project write-up by Yan Hui</a>), born out of an AI+art hackathon “<a href="https://www.caa-ins.org/archives/11595" target="_blank" style="background-color:purple; color:white;">AIathon</a>.” It introduces a new perspective on perception and interaction as a multi-agent system, working with text-image-video AI models.
      <br><br>
      <em>“I am VITIV.”
      <br>“I am a ____.”
      <br>“I see the world with you.”</em>
      </p>

      <p style="font-size: 14px;">
        As a multi-agent system, VITIV engages with humans/artists through its camera lens, offering a unique dialogue about shared “observations.” Named after the Video-to-Image-to-Text-to- Image-to-Video model it employs, VITIV represents a dynamic feedback loop between intelligent agents. This reflective process influences evaluation systems and enhances our collective ability to perceive and create, or imagine.
      <br><br>
        At its current prototype stage as a web application, VITIV presents a live video feed on the browser, allowing users to inquire about the captured images. Asking questions like "What do you see?" initiates the conversation with the system, where it responds based on the captured image. This exchange of thoughts and vision can continue, and at any point, users can request VITIV to generate a video reflecting its vision, in parallel to the live video feed its camera lens captures as well as what our human eyes see.
      <br><br>
        The models we’re currently working with are <a href="https://github.com/THUDM/CogVLM" target="_blank" style="background-color:white; color:black;">CogVLM</a>, an open-source visual language model developed by Zhipu AI and Tsinghua University, which will generate text from captured image, and <a href="https://runwayml.com/research/gen-2" target="_blank" style="background-color:white; color:black;">Runway Gen-2</a>, which takes both text and image to generate videos. Though both VITIV’s input and output are in forms of video, it is important to go through the models with using image and its captioning with natural language, instead of directing training an image to image model. The first step of the work is to critically understand the image/video visual culture we’re working with in description of the natural languages humans have used to construct the world with.
      </p>

      <p style="margin-top: 40px;">
        ***
        <br><br>
        This project started at a hackathon named “AIathon” as the kick-off event of its 8th Annual Conference of Network Society, “Counter-Culture? Resetting all (im)possibilities of Technology,“ hosted by the Institute of Network Society in the School of Intermedia Art at China Academy of Art. The hackathon was 48 hours happened on November 4th & 5th, 2023 and took place at the Zhangjiang Science Hall in Shanghai.
        <br><br>
        VITIV was given an “Inventor Award” among four prized projects at “AIathon.”
        <br><br>
        VITIV was also presented at the Eighth Annual Conference of Network Society, (<a href="https://youtu.be/xgDYlLoBd44?t=19469" target="_blank" style="background-color:white; color:purple;">live video archive from the timecode, 5:24:29 to 5:36:58</a>)
      </p>
    </div>

    <div class="page-gallery">

    </div>



  
  </body>
</html>